{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entendiendo el gradiente descendente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los algoritmos de optimización por gradiente descendente son cada vez más populares, y a menudo son utilizados como cajas negras con explicaciones prácticas de sus fortalezas y sus debilidades. El objetivo de este artículo es proporcionarle al lector una pequeña intuición y los conocimientos mínimos en matemáticas para entender mejor el comportamiento de estos algoritmos y tener criterios sólidos para ponerlos en uso. En el curso de esta descripción general, estudiaremos las diferentes variantes de los gradientes descendentes y sus principales desafios. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El aprendizaje mecánico y la estadística comparten importantes características, pero usan una terminología diferente. En estadística, la regresión lineal se utiliza para modelar una relación $\\mathcal{R}\\subseteq\\mathcal{X}\\times\\mathcal{Y}$ a partir  de una muestra de datos $S\\subset \\mathcal{R}\\subseteq\\mathcal{X}\\times\\mathcal{Y}\\subseteq\\mathbb{R}^{m+1}\\times\\mathbb{R}$. Usualmente los datos que provienen de $\\mathcal{X}$ se denominan <em>variables independientes</em> y los que provienen de $\\mathcal{Y}$ se denominan <em>variables dependientes</em>. En el contexto del aprendizaje mecánico, este es llamado un <em>problema de aprendizaje supervisado</em>. El conjunto $S=\\{(x_i, y_i)\\}_{i=0}^{k}$ se denomina <em>conjunto de entrenamiento</em> y el par de valores $(x_i, y_i)$ es un <em>ejemplo de entrenamiento</em> del conjunto $S$ de $k$ ejemplos de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada $x_i$ es considerado como un vector columna de la forma $x_i=(1, x_{i,1},\\dots,x_{i,m})^{\\top}$ de dimensión $m+1$, a menudo es referido como el predictor en la literatura estadística. El proposito de la regresión lineal es identificar el mejor <em>predictor</em> de la clase de predictores de la forma $y =\\theta^{\\top} x$, donde $\\theta \\in \\mathbb{R}^{m+1}$ y es de la forma $\\theta =(\\theta_0, \\dots, \\theta_m)^\\top$, el parámetro $\\theta_0$ se denomina <em>bias</em>. Para hacer esto, se considera la matriz $X\\in M_{k\\times m+1}(\\mathbb{R})$ donde la $i$ - ésima fila está dada por el $i$ - ésimo vector fila $x_i^{\\top}$. De esta manera se obtiene una expresión general para predecir los valores de $\\mathcal{Y}$ que viene dada por el modelo:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\\nonumber\n",
    "Y=X\\theta.\n",
    "\\end{equation} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En Python podemos definir la clase de predictores lineales $y =\\theta^{\\top} x$ de la siguiente forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class LinearPredictor:\n",
    "    \n",
    "    def __init__(self, m):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            theta: initial predictor.\n",
    "            \n",
    "        Output:\n",
    "            None.\n",
    "        \"\"\"\n",
    "        \n",
    "        # The coefficient column vector is initialized to zero.\n",
    "        self.theta = np.zeros(m + 1).reshape(-1, 1)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            x: list of float values of the form [1, x_1, ... ,x_m].\n",
    "            \n",
    "        Output:\n",
    "            Returns the dot product (float) between «theta» and «x». \n",
    "        \"\"\"\n",
    "        \n",
    "        # We define theta as self.theta.\n",
    "        theta = self.theta        \n",
    "        # Convert «x list» to a column vector.\n",
    "        x = np.array(x).reshape(-1, 1)\n",
    "        \n",
    "        # Returns the product of the matrices theta and x.\n",
    "        return float(theta.T.dot(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que en el código anterior, el vector de coeficientes $\\theta$ se puede inicializar a elección del lector, lo importante aquí, es ir actualizandolo hasta encontrar el mejor de ellos. Este problema de encontrar el mejor predictor lineal se resuelve eligiendo algún vector de coeficientes $\\theta$ que minimizan la suma residual de cuadrados:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\\nonumber\n",
    "E_S(\\theta)=(Y-X\\theta)^\\top (Y-X\\theta).\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la ecuación anterior, $Y$ es el vector columna  donde la $i$ - ésima entrada está dada por cada la etiqueta $y_i$  definida en el conjunto de entrenamiento $S$, es decir, $Y = (y_1,\\dots, y_k)^\\top$. Esto permite definir el problema como un problema de minimización del riesgo empirico (ERM) dado por:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "\\begin{equation}\\tag{1}\n",
    "ERM_{\\theta}(S)\\equiv \\operatorname*{argmin\\,\\,}_{ \\theta \\in \\mathbb{R}^{m+1}} E_{S}(\\theta),\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "que es equivalente a  escoger un vector $\\hat{\\theta}\\in ERM_{\\theta}(S)$ para la solución del problema de optimización en la [Ecuación 1](#1). Para estudios de simulación, se puede construir un modelo sintético a partir de la generación de datos con: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "\\begin{equation}\\tag{2}\n",
    "Y=X\\xi + \\epsilon,\n",
    "\\end{equation} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "donde $\\epsilon\\sim \\mathcal{N}(0, \\sigma^2I_{k})$. Esto se pueden implementar fácilmente en Python de la siguiente forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyntheticData:\n",
    "\n",
    "    def __init__(self, m):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            m: dimension of the space of independent variables.\n",
    "            \n",
    "        Output:\n",
    "            None.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Dimensión of the data.\n",
    "        self.m = m\n",
    "        \n",
    "        # The vector of coefficients is chosen at random.\n",
    "        self.xi = np.random.rand(m + 1).reshape(-1, 1)        \n",
    "          \n",
    "    def generate(self, k, sigma):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            k: the amount of data to generate.\n",
    "            sigma: standard deviation.\n",
    "            \n",
    "        Output:\n",
    "            Returns a tuple with X, y and xi.\n",
    "        \"\"\"\n",
    "        \n",
    "        # A column vector of ones is constructed.\n",
    "        ones = np.ones(k).reshape(-1, 1)\n",
    "        \n",
    "        # Random data is generated and added to the ones vector.\n",
    "        X = np.hstack((ones, np.random.rand(k, self.m)))\n",
    "        \n",
    "        # Random noise is generated.\n",
    "        epsilon = sigma * np.random.standard_normal(k)\n",
    "        \n",
    "        # Values for y are constructed.\n",
    "        y = X.dot(self.xi) + epsilon.reshape(-1, 1)\n",
    "\n",
    "        return X, y, self.xi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para entender el comportamiendo del gradiente de descente es conveniente probar con diferentes colecciones de datos o lotes, para eso sea:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\\nonumber\n",
    "    S_{l}=\\{X_{l}, Y_{l}\\}_{l\\in[r]_{\\mathbb{N}_0}}, \n",
    "\\end{equation} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "una colección de $r$ simulaciones[<sup>1](#3). En Python podemos hacer una implementación sencilla para generar estos lotes de datos, esto sería algo así:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batches(m, k, r, sigma):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        m: dimension of the space of independent variables.\n",
    "        size_data: the amount of data to generate by batch.\n",
    "        batchs: number of batchs.\n",
    "        sigma: standard deviation.\n",
    "    \n",
    "    Output: \n",
    "        List with generated batches.        \n",
    "    \"\"\"\n",
    "    \n",
    "    # We generate the synthetic data for each batch.\n",
    "    synthetic_data = SyntheticData(m)\n",
    "    batches = [synthetic_data.generate(k, sigma) for _ in range(r)]\n",
    "    \n",
    "    return batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de la ecuación [Ecuación 1](#1) es encontrar un vector $\\hat{\\theta}\\in ERM_{\\theta}(S)$ , para nuestro ejercicio esto se traduce en estimar el vector $\\hat{\\theta}$ tan cerca como sea posible al parámetro conocido $\\xi$ del modelo simulado en la [Ecuación 2](#2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El indicador que se utilizará para comparar la estimación de los coeficientes $\\hat{\\theta}$ con los coeficientes verdaderos $\\xi$ será el error cuadrático medio (RMSE). Esta medición se utilizará para evaluar el rendimiento en cada una de la simulaciones $S_l$. Tenga en cuenta que el RMSE se calculan para un elemento específico en el vector $\\theta$. La notación $\\operatorname{RMSE}_d$ enfatizará a qué parámetro se refiere. Para los parámetros $d\\in [m]_{\\mathbb{N_0}}$, considere:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\operatorname{RMSE}_d = \\left(\\frac{1}{r}\\sum_{j=0}^{r}\\big(\\theta^{(d)}_j-\\xi^{(d)}\\big)^{2}\\right)^{\\frac{1}{2}}.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así se obtiene $\\operatorname{RMSE} = (\\operatorname{RMSE}_0,\\dots, \\operatorname{RMSE}_{m})$. En Python se tendría algo así:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(matrix_theta: list, xi: list, r: int) -> np.array:\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        matrix_theta: this a matrix of values theta for each S.\n",
    "        xi: synthetic parameters.\n",
    "        r: number of simulations. \n",
    "        \n",
    "    Output:\n",
    "        RMSE\n",
    "    \"\"\"\n",
    "    \n",
    "    matrix_theta = np.array(matrix_theta)\n",
    "    xi = np.array(xi).reshape(-1, 1)\n",
    "    arg = 1/r * (matrix_theta - xi)**2\n",
    "    \n",
    "    return np.sqrt(arg.sum(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el código anterior se espera como parámetro de entrada una matriz $\\Theta$ donde cada $l$ - ésima columan es el $l$ - vector de coeficientes aprendido para la $l$ - ésima simulación de datos $X_{l}$, esto se explicará con más detalle a continuación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si se asume que $h_{\\theta}$ es un predictor para el conjunto de datos $S_{l}=\\{X_{l}, y_{l}\\}$, entonces el problema de regresión lineal en la [Ecuación 1](#1) se puede reescribir con la siguiente función de perdida:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\\tag{3}\n",
    "E_{S}(\\theta)=\\frac{1}{2k}\\sum_{i=1}^{k}\\big(h_{\\theta}(x_i)-y_i\\big)^2.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta función para la perdida es facil de implementar en Python como podemos ver a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(predictor, sample: tuple) -> float:\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        predictor: linear predictor. \n",
    "        sample: dataset.\n",
    "    \n",
    "    Output:\n",
    "        loss.    \n",
    "    \"\"\"\n",
    "    \n",
    "    arg = list()\n",
    "    k = len(sample[0])\n",
    "    \n",
    "    for i in range(k):\n",
    "        x_i = sample[0][i]\n",
    "        y_i = sample[1][i]\n",
    "        k = len(sample[0])\n",
    "        arg.append((predictor.predict(x_i) - y_i)**2)\n",
    "        \n",
    "    return 1/(2*k) * sum(arg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una forma de resolver este problema es utilizar los métodos del gradiente descente. Estos son algoritmos que hacen uso de las derivadas parciales de funciones direfenciales convexas y, como cualquier algoritmo, su eficiencia puede ser monitoreada. Principalmente, la eficiencia de un algoritmo depende de que tan precisa es la estimación que produce. En segungo lugar, se analiza su capacidad para producir tal estimación dentro de un marco de tiempo factible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los métodos del gradiente descendente produce secuencias finitas de números $\\theta$. Para ser eficiente esta secuencia debería converger al valor óptimo. En este ejercicio, para algún $\\delta > 0$, la eficacia de un algoritmo se evalúa midiendo la duración para producir una estimación $\\hat{\\theta}$ con precisión $\\delta$ tal que:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "||\\hat{\\theta}-\\xi||<\\delta\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En lugar de una respuesta continua $y$, la respuesta podría ser binaria, es decir, $y \\in \\{0, 1\\}$. En estadística, este es un modelo de regresión logística. Dados ciertos predictores, también es un problema de aprendizaje supervisado. Las premisas para resolver un problema de regresión logística son similares a las de un problema continuo. En el caso binario el problema se resuelve para la siguiente función de perdida:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4'></a>\n",
    "\\begin{equation}\\tag{4}\n",
    "E_{S}(\\theta) = \\frac{1}{m}\\bigg(\\sum_{i=1}^{m}\\Big(y_i\\log h_{\\theta}\\big(x_i\\big) + \\big(1-y_i\\big)\\log \\big(1 - h_{\\theta}\\big(x_i\\big)\\big)\\Big)\\bigg)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "donde"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "h_{\\theta}(x) = \\frac{1}{1+e^{-\\theta^\\top x}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta es una función convexa y suave. Por lo tanto, el proceso de solución es similar al de [Ecuación 1](#1). Pero aquí, la variable dependiente $y$ es categórica. Si $y$ tiene más de dos resultados posibles, el modelo se llama regresión logística multinomial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradiente descendente (GD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcular la solución del objetivo de optimización se logra minimizando la función de costo $E_{S}(\\theta)$. Su gradiente se representa por $\\nabla E_{S}(\\theta)$ y revela en cual direción la función decrese más rápido (<a src ='https://alejandrosanchezyali.blogspot.com/2020/10/algoritmo-del-gradiente-descendente.html'>Ver Gradiente Descendente</a>). Utilizando $\\nabla E_{S}(\\theta)$ es posible dar pasos repetidamente hacia un mínimo local. Esto sugiere el siguiente algoritmo: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Algoritmo 1. Gradiente Descendente Clásico*\n",
    "<blockquote>    \n",
    "Input: $\\theta$, $X$, $Y$, $t$, $ \\alpha$, $\\nabla E_{S}$\n",
    "<br>1. &nbsp; &nbsp;&nbsp;for $k=0$ to $p$ do:\n",
    "<br>2. &nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;$\\theta\\leftarrow \\theta - \\alpha \\nabla E_{S}(\\theta, X, Y)$\n",
    "<br>3. &nbsp; &nbsp;&nbsp;end    \n",
    "<br>return: $\\theta$\n",
    "\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el seudocódigo anterior se tiene que $t$ es el número máximo de iteraciones y $\\alpha$  es la tasa de aprendizaje, hiperparámetros que son ajustados manualmente. Hay métodos que  permite aproximar la tasa de aprendizaje  para acelerar la convergencia, pero aquí en nuestro caso,  el descenso del gradiente se mantendrá en su forma pura. Cuando $\\alpha$ se elige lejos de su valor óptimo $\\alpha^*$, el algoritmo divergerá si $\\alpha > \\alpha^*$ y convergerá muy lentamente si $\\alpha < \\alpha^*$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos la función objetivo $E(\\theta)$ en [Ecuación 1](#1). Sea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "h_{\\theta}(x)= \\theta^\\top x\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si el número de ejemplos de entrenamiento es $k$, el número de parámetros es $m+1$, entonces entonces considerando $j=0, \\cdots, m$ y $e_0,\\dots,e_m$ la base estandar, entonces el gradiente de $E_{S}(\\theta)$ se puede expresar como:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\nabla E_{S}(\\theta) = \\sum_{i=0}^{m}\\frac{\\partial E}{\\partial \\theta_{i}}e_{i}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "donde"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\frac{\\partial E_{S}}{\\partial \\theta_{j}}=\\frac{1}{k}\\sum_{i=1}^{k}\\big(\\theta^\\top x_i-y_i\\big)x_{i,j}.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La convergencia del algoritmo del gradiente descendente depende de la elección precisa de la tasa de aprendizaje $\\alpha$, así como del número suficiente de iteraciones $t$. Nuestro caso es un problema de optimización convexo y tomando hiperparámetros apropiados, es decir $0<\\alpha <1$, el algoritmo debería converger. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la [Ecuación 4](#4), el objetivo es la optimización para la regresión logística, la función de costo es otra, pero nuevamente podemos obtener el gradiente de la siguiente manera:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\frac{\\partial E_{S}}{\\partial \\theta_{j}}=\\frac{1}{k}\\sum_{i=1}^{k}\\big(h_{\\theta}(x)-y_i\\big)x_{i,j},\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "donde $h_{\\theta}(x) = \\frac{1}{1+e^{-\\theta^\\top x}}$. Como la ecuación $E_{S}(\\theta)$ para la regresión logistica vuelve a ser una función convexa, entonces se puede usar los algoritmos basados en el gradiente para minimizar la [Ecuación 4](#4)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se presenta la implementación del algoritmo del gradiente descendente en python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gd(predictor, X, Y, t, alpha, gradient):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        predictor: it's a predictor function.\n",
    "        X: it's a matrix with the independent data.\n",
    "        Y: it's a matrix with the dependent data.\n",
    "        t: it's the maximum number of iterations. \n",
    "        alpha: it's the learning rate.\n",
    "        gradient: it's a gradient function of the predictor function.\n",
    "    \"\"\"\n",
    "    \n",
    "    theta = predictor.theta\n",
    "    iterations = 0\n",
    "    \n",
    "    while iterations <= t:\n",
    "        theta = theta - alpha * gradient(theta, X, Y)\n",
    "        iterations += 1\n",
    "        \n",
    "    predictor.theta = theta\n",
    "    \n",
    "    return predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradiente descendente estocástico (SGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otro algoritmo para resolver problemas de optimización es la versión estocástica del gradiente descendente. En este caso en lugar de evaluar sobretodo el conjunto de entrenamiento $S$, en cada iteración se selecciona aleatoriamente un solo ejemplo $(x_{i_k}, y_{i_k})$, de manera que el gradiente estocástico sería:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\nabla E_{S}^{sg}(\\theta) = \\sum_{i=0}^{m}\\frac{\\partial E_{S}(\\theta, x_{i_k}, y_{i_k})}{\\partial \\theta_{j}}e_{j},\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "en donde:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\frac{\\partial E_{S}(\\theta, x_{i_k}, y_{i_k})}{\\partial \\theta_{j}} = (h_{\\theta}(x_{i_k}) -  y_{i_k})x_{i_k, j}.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La elección de ${i_k}$ se puede elegir mediante alguna de las siguientes reglas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Elección aleatoria: escoger $i_k\\in \\{1,2,\\dots, m\\}$ asumiendo una distribucción uniforme.\n",
    "2. Elección cíclica: seleccionar ${i_k}=1, 2,\\dots, m, 1, 2,\\dots, m,\\dots$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La elección aleatoria es la más común en la práctica. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo tanto, el ciclo se puede inicializar en uno y finalizará cuando se alcance el número máximo de epocas $t$. Este algoritmo tiene la siguiente esquema:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Algoritmo 2. Gradiente Descendente Estocástico*\n",
    "<blockquote>    \n",
    "Input: $\\theta$, $X$, $Y$, $t$, $ \\alpha$, $\\nabla E_{S}$, $index\\_rule$\n",
    "<br>1. &nbsp;&nbsp;&nbsp;for $k=1$ to $t$ do:\n",
    "<br>2. &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;$i_k = index\\_rule(X)$\n",
    "<br>3. &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;$\\theta\\leftarrow \\theta - \\alpha \\nabla E_{S}(\\theta, x_{i_k}, y_{i_k})$\n",
    "<br>4. &nbsp;&nbsp;&nbsp;&nbsp;end    \n",
    "<br>return: $\\theta$\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que el algoritmo 2, $k$ denota el cantidad de datos en el conjunto $S$, consecuentemente, cada epoca recorre todos los elementso de $S$. Este algoritmo tambien se aplica para resolver el problema de la regresión logística. Un implementación rápida de este algoritmo sería:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "\n",
    "def sdg(predictor, initial_theta, X, Y, t, alpha, gradient, index_rule):\n",
    "    theta = predictor.theta\n",
    "    iterations = 0\n",
    "    indexes = np.arange(X.shape[0]).tolist()\n",
    "        \n",
    "    if index_rule == 'randomized_rule':\n",
    "        \n",
    "        while iterations <= t:\n",
    "            i_k = np.random.choice(indexes)\n",
    "            theta = theta - alpha * gradient(theta, X[i_k], Y[i_k])\n",
    "            iterations += 1\n",
    "            \n",
    "    elif index_rule == 'cyclic_rule':\n",
    "        \n",
    "        pool = cycle(indexes)\n",
    "        while iterations <= t:\n",
    "            i_k = next(pool)\n",
    "            theta = theta - alpha * gradient(theta, X[i_k], Y[i_k])\n",
    "            iterations += 1\n",
    "    else:\n",
    "        raise Exception('A suitable rule has not been defined')\n",
    "            \n",
    "        \n",
    "    predictor.theta = theta\n",
    "    return predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradiente descendente estocástico por minilotes (Mini-Batch SGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otro versión del gradiente descendente y que a menudo logra un mejor rendimiento que SGD y GD es ejecutar el algoritmo por pequeñas partes de los datos. Una parte de los datos se denomina minilote (Mini-batch), mientras que todo el conjunto de entrenamiento $S$ se denomina lote. Estos minilotes se generan seleccionando aleatoriamente los vectores fila de la matriz $X$. El esquema general de este algoritmo sería:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Algoritmo 3. Gradiente Descendente Estocástico por lotes*\n",
    "<blockquote>    \n",
    "Input: $\\theta$, $X$, $Y$, $t$, $ \\alpha$, $\\nabla E_{S}$, $size\\_batch$\n",
    "<br>1. &nbsp;&nbsp;&nbsp;for $k=1$ to $t$ do:\n",
    "<br>2. &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;$[i_{0, k}, \\dots, i_{size\\_batch, k}] = choose\\_indexes(X)$\n",
    "<br>3. &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;$\\theta\\leftarrow \\theta - \\alpha \\nabla E_{S}(\\theta, X[i_{0, k}, \\dots, i_{size\\_batch, k}], Y[i_{0, k}, \\dots, i_{size\\_batch, k}])$\n",
    "<br>4. &nbsp;&nbsp;&nbsp;&nbsp;end    \n",
    "<br>return: $\\theta$\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuitivamente el algoritmo converge si SGD converge. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sdg_mini_batch(initial_theta, X, Y, t, alpha, gradient, size_batch):\n",
    "    theta = predictor.theta\n",
    "    iterations = 0\n",
    "    indexes = np.arange(X.shape[0]).tolist()\n",
    "        \n",
    "    while iterations <= t:\n",
    "        indexes_batch = np.random.choice(indexes, size_batch)\n",
    "        sgrad = gradient(theta, X[indexes_batch], Y[indexes_batch])\n",
    "        theta = theta - alpha * sgrad     \n",
    "        iterations += 1\n",
    "        \n",
    "    predictor.theta = theta\n",
    "    return predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulaciones en ambientes controlados para la regresión lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación vamos a analizar el comportamiento de los algorimos 1, 2, 3 en un ambiente controlado de regresión lineal. Para esto vamos a generar varios datos de prueba, en los cuales podemos conocer el valor de $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Análisis con 30 lotes de 200 datos de la forma $(x, y)\\in \\mathbb{R}^2$  y un ruido del 5%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 3\n",
    "batches = generate_batches(m=m, k=200, r=10, sigma=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(theta, xi):\n",
    "    arg = theta - xi\n",
    "    return np.linalg.norm(arg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para hacer el análisis de los algoritmos GD, SGD SGD MINI-BATCH, se hace unas pequeñas modificaciones para medir la evolución de la perdida o error en cada una de las iteraciones. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gradiente descendente clásico moficado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gd(predictor, X, Y, t, alpha, gradient, loss=None, xi=None):\n",
    "    \n",
    "    theta = predictor.theta\n",
    "    iterations = 0    \n",
    "    \n",
    "    if loss is not None:\n",
    "        delta_theta = list()\n",
    "        deltas_thetas = theta.reshape(-1, 1) - xi.reshape(-1, 1)\n",
    "    \n",
    "    if loss is not None: \n",
    "        errors = list()\n",
    "        sample = tuple([X, Y])\n",
    "    \n",
    "    while iterations <= t:\n",
    "        \n",
    "        theta = theta - alpha * gradient(theta, X, Y)\n",
    "        predictor.theta = theta\n",
    "        \n",
    "        if loss is not None:            \n",
    "            errors.append(loss(predictor=predictor, sample=sample))\n",
    "            \n",
    "        if loss is not None:\n",
    "            delta_theta.append(euclidean_distance(theta, xi))\n",
    "            arg = theta-xi\n",
    "            deltas_thetas = np.hstack((deltas_thetas, arg))\n",
    "            \n",
    "        iterations += 1   \n",
    "        \n",
    "    return predictor, errors, delta_theta, deltas_thetas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gradiente descendente estocástico moficado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "\n",
    "def sgd(predictor, X, Y, t, alpha, gradient, index_rule, loss=None, xi=None):    \n",
    "\n",
    "    theta = predictor.theta\n",
    "    iterations = 0\n",
    "    indexes = np.arange(X.shape[0]).tolist()   \n",
    "    \n",
    "    if loss is not None:\n",
    "        delta_theta = list()\n",
    "        deltas_thetas = theta.reshape(-1, 1) - xi.reshape(-1, 1)\n",
    "    \n",
    "    if loss is not None: \n",
    "        errors = list()\n",
    "        sample = tuple([X, Y])  \n",
    "        \n",
    "    if index_rule == 'randomized_rule':\n",
    "        \n",
    "        while iterations <= t:\n",
    "            i_k = np.random.choice(indexes)\n",
    "            theta = theta - alpha * gradient(theta, X[i_k], Y[i_k])\n",
    "            predictor.theta = theta\n",
    "            \n",
    "            iterations += 1\n",
    "            \n",
    "            if loss is not None:            \n",
    "                errors.append(loss(predictor=predictor, sample=sample))\n",
    "\n",
    "            if loss is not None:\n",
    "                delta_theta.append(euclidean_distance(theta, xi))\n",
    "                arg = theta-xi\n",
    "                deltas_thetas = np.hstack((deltas_thetas, arg))\n",
    "            \n",
    "    elif index_rule == 'cyclic_rule':\n",
    "        \n",
    "        pool = cycle(indexes)\n",
    "        while iterations <= t:\n",
    "            i_k = next(pool)\n",
    "            theta = theta - alpha * gradient(theta, X[i_k], Y[i_k])\n",
    "            predictor.theta = theta\n",
    "            \n",
    "            iterations += 1\n",
    "            \n",
    "            if loss is not None:            \n",
    "                errors.append(loss(predictor=predictor, sample=sample))\n",
    "\n",
    "            if loss is not None:\n",
    "                delta_theta.append(euclidean_distance(theta, xi))\n",
    "                arg = theta-xi\n",
    "                deltas_thetas = np.hstack((deltas_thetas, arg))\n",
    "                \n",
    "    else:\n",
    "        raise Exception('A suitable rule has not been defined')\n",
    "            \n",
    "        \n",
    "    predictor.theta = theta\n",
    "    return predictor, errors, delta_theta, deltas_thetas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gradiente descendente estocástico minibatch modificado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sdg_mini_batch(predictor, X, Y, t, alpha, gradient, size_batch, loss=None, xi=None):\n",
    "    theta = predictor.theta\n",
    "    iterations = 0\n",
    "    indexes = np.arange(X.shape[0]).tolist()\n",
    "    \n",
    "    if loss is not None:\n",
    "        delta_theta = list()\n",
    "        deltas_thetas = theta.reshape(-1, 1) - xi.reshape(-1, 1)\n",
    "    \n",
    "    if loss is not None: \n",
    "        errors = list()\n",
    "        sample = tuple([X, Y])  \n",
    "        \n",
    "    while iterations <= t:\n",
    "        indexes_batch = np.random.choice(indexes, size_batch)\n",
    "        sgrad = gradient(theta, X[indexes_batch], Y[indexes_batch])\n",
    "        theta = theta - alpha * sgrad \n",
    "        \n",
    "        if loss is not None:            \n",
    "            errors.append(loss(predictor=predictor, sample=sample))\n",
    "\n",
    "        if loss is not None:\n",
    "            delta_theta.append(euclidean_distance(theta, xi))\n",
    "            arg = theta-xi\n",
    "            deltas_thetas = np.hstack((deltas_thetas, arg))\n",
    "        \n",
    "        iterations += 1\n",
    "        \n",
    "    predictor.theta = theta\n",
    "    return predictor, errors, delta_theta, deltas_thetas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gradiente para la regresión lineal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(theta, X, Y):\n",
    "    if len(X.shape)==1:\n",
    "        X = X.reshape(1, -1)\n",
    "    return X.T.dot((X.dot(theta)- Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_theta = list()\n",
    "errors = list()\n",
    "deltas_theta = list()\n",
    "deltas = list()\n",
    "xi = batches[0][2]\n",
    "for batch in batches:\n",
    "    X = batch[0]\n",
    "    Y = batch[1]\n",
    "\n",
    "    predictor = LinearPredictor(m)\n",
    "    parameters = dict(\n",
    "        predictor=predictor,\n",
    "        X=X,\n",
    "        Y=Y,\n",
    "        t=200,\n",
    "        alpha=0.001,\n",
    "        gradient=gradient,\n",
    "        index_rule='randomized_rule',\n",
    "        # size_batch=None,\n",
    "        loss=loss,        \n",
    "        xi=xi\n",
    "    )\n",
    "    predictor, error, delta_theta, delta = sgd(**parameters)\n",
    "    errors.append(error)\n",
    "    deltas.append(delta)\n",
    "    deltas_theta.append(delta_theta)\n",
    "    matrix_theta.append(predictor.theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_theta = np.array(matrix_theta)\n",
    "matrix_theta = matrix_theta.squeeze().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE(matrix_theta=matrix_theta, xi=xi, r=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "i = 0\n",
    "for error in errors:\n",
    "    plt.plot(error, label='iter {}'.format(i))\n",
    "    plt.legend()\n",
    "    plt.title('Loss vs Iterations')\n",
    "    plt.xlabel('N° Iterations')\n",
    "    plt.ylabel('Loss Function')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for delta_theta in deltas_theta:\n",
    "    plt.plot(delta_theta, label='iter {}'.format(i))\n",
    "    plt.legend()\n",
    "    plt.title(r'Distance between $\\theta$ and $\\xi$')\n",
    "    plt.xlabel('N° Iterations')\n",
    "    plt.ylabel('Distance')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(8, 8))\n",
    "batches = len(deltas)\n",
    "switch = True\n",
    "for j in range(m + 1):\n",
    "    for k, axis in enumerate(axs.flat):\n",
    "        for i in range(batches):\n",
    "            if j == k:\n",
    "                axis.plot(deltas[i][j])\n",
    "                axis.set_title(r'$\\theta_{}$'.format(j))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltas[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliografía\n",
    "1. Sebastián Ruder. 2017. An overview of gradient descent optimization algorithms. Insight Centre for Data Analytics, Nui Galway.\n",
    "2. https://mmuratarat.github.io/2019-01-07/logistic-regression-in-Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notas\n",
    "<a id=\"1\">[1]</a>. El conjunto $[r]_{\\mathbb{N}_0}$ es $\\{0, 1, 2,\\dots, r\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "fig = plt.figure(figsize=(15, 15)) \n",
    "# create figure window\n",
    "\n",
    "gs = gridspec.GridSpec(2, 3)\n",
    "# Creates grid 'gs' of a rows and b columns \n",
    "\n",
    "\n",
    "ax = plt.subplot(gs[1, 1])\n",
    "ax.plot([1, 2], [3, 4])\n",
    "ax = plt.subplot(gs[1, 2])\n",
    "ax.plot([1, 2], [3, 4])\n",
    "fig.add_subplot(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(19680801)\n",
    "data = np.random.randn(2, 100)\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(5, 5))\n",
    "axs[0, 0].hist(data[0])\n",
    "axs[1, 0].scatter(data[0], data[1])\n",
    "axs[0, 2].plot(data[0], data[1])\n",
    "axs[1, 1].hist2d(data[0], data[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "6 // 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " a = [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltas[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1,2], [3, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array([1, 2]).reshape(-1, 1)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.T.dot(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
