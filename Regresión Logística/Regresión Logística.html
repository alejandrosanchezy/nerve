<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Regresi&#243;n-log&#237;stica-y-el-problema-de-clasificaci&#243;n">Regresi&#243;n log&#237;stica y el problema de clasificaci&#243;n<a class="anchor-link" href="#Regresi&#243;n-log&#237;stica-y-el-problema-de-clasificaci&#243;n">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>La regresión lineal asume que existe una relación lineal entre dos variables $\mathcal{X}$ y $\mathcal{Y}$. Pero esto se viola rápidamente cuando la variable dependiente, $\mathcal{Y}$ es una variable categórica. La <strong>regresión logística</strong> expresa la regresión lineal múltiple en terminos de un logaritmo, superando así la no linealidad.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>La regresión logística es uno de los métodos que se usan para el problema de clasificación. Usualmente se usa para estimar la probabilidad de que una <strong>muestra</strong> sea parte de una clase en particular (por ejemplo, ¿Cuál es la probabilidad de que una persona padeza cancer?). Si la probabilidad estimada es mayor que $50\%$, entonces el modelo predice que la <strong>muestra</strong> pertenece a esa clase y sino entonces predice que no pertenece. Esto es lo que hace en principio un clasificador binario.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Como se mencióno al principio, el modelo de regresión lineal se comporta pobremente cuando la variable $\mathcal{Y}$ es una variable discreta o categórica. Para resolver esto, hay que cambiar la forma de la hipótesis $h_{\theta}(x)$. Para esto se toma la familia de predictores de la forma, 
$$h_{\theta}(x) = \sigma(\theta^\top x) = \frac{1}{1 + e^{\theta^\top x}},$$
donde
$$\sigma(z) = \frac{1}{1 + e^{-z}}$$
es la <strong>función logística</strong> o la <strong>función sigmoide</strong>. Graficamente $\sigma(z)$ luce de la siguiente forma:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">)</span>
<span class="n">g_z</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">g_z</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Figura 1. Función Sigmoide&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Observe que $\sigma(z)$ tiene a $1$ cuando $z\to \infty$, y $\sigma(z)$ tiene a $0$ cuándo $z\to -\infty$. Ademas, $\sigma(z)$, y por lo tanto $h_{\theta}$ está acotada entre $0$ y $1$. Acá se sigue manteniendo la convención de que $\theta = (\theta_0, \dots, \theta_n)^{\top}$ y $x=(1, x_1, \dots, x_n)^{\top}$, asi que $\theta^{\top}x=\theta\cdot x$.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Estimando-probabilidades">Estimando probabilidades<a class="anchor-link" href="#Estimando-probabilidades">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Considere una conjunto de datos $S=\{(x_i, y_i)\}_{i=1}^m$, donde cada $x_i = (1, x_{i,1}, \dots, x_{i,n})^{\top}$ y cada $y_{i}\in \{0, 1\}$. Bajo estas condiciones, la variable $y_i$ se puede ver como una distribución de Bernoulli para la clasificación binaria. La regresión logística dice que la probabilidad de que la variable $y_i=1$, para $i=1,2, \dots, m$ puede ser modelado así:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$ h_{\theta}(x_i)=E[y_i\,|\,x_i]=P(y_i=1\,|\,x_i, \theta)=\sigma(\theta^\top x_i)$$
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>donde $\sigma$ representa la función sigmode. ¿Pero esto por qué es así?</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>La razón viene de la generalización de los modelos lineales. Dado que $y_i$ es una variable binaria, parece natural la elección de una familia de distribuciones de Bernoulli para el modelo de probabilidad condicional de $y_i$ dado $x_i$. En la formulación de la distribución de Bernoulli como una familia de distribuciones exponenciales, se tiene que $p=\frac{1}{1 + e^{-\eta}}$ donde $\eta = \theta^\top x_i$. Además, observe que si $y_i\,|\, x_i; \theta \sim Ber(p)$, entonces $E[y_i\, |\, x_i]=p$.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Al asumir que $P(y_i=1\,|\,x_i;\theta)=h_{\theta}(x_i)$ y $P(y_i=0\,|\,x_i;\theta)=1 - h_{\theta}(x_i)$. Entonces de forma más compacta se puede escribir que:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$P(y_i\,|\,x_i; \theta)=(h_{\theta}(x_i))^{y_i}(1-h_{\theta}(x_i))^{1-y_i}.$$
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Como desde antes se ha asumido que se tiene un conjunto de entrenamiento con $m$ muestras que se supone han sido generadas independientemente, entonces la verosimilitud de los parámetros se puede expresar como:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$L(\theta)=p(y\,|\, X; \theta) = \prod_{i=1}^{m}p(y_i\,|\,x_i; \theta),$$
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>donde $y=(y_1, \dots, y_m)^{\top}$ y $X$ es la matriz cuyas filas son $x_i^{\top}$ para todo $i=1, \dots, m$.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>El objetivo es maximizar la verosimilitud $L(\theta)$, para esto es más fácil maximizar su logaritmo, es decir:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$l(\theta) = \log L(\theta) = \sum_{i=1}^{m} y_{i}\log h_{\theta}(x_i)+(1+y_i)\log(1 - h_{          \theta}(x_i)).$$
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Como en la regresión lineal para encontrar el parámetro $\theta$ hay que minimizar la función de costo, aquí también se mantiene la consistencia, ya que este problema se puede ver como un problema de minimización. Para esto consideramos el costo promedio sobre todo el conjutno de datos. En este caso, se considera $l(\theta)$. La maximización de $l(\theta)$ es equivalente a la minimización de $-l(\theta)$. Y usando la función promedio sobre todo el conjunto de datos, la función de costos para la regresión toma la forma:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$J(\theta)=-\frac{1}{m}L(\theta)=-\frac{1}{m}\sum_{i=1}^{m}y_{i}\log(h_{\theta}(x_i)) + (1-y_i)\log(1-h_{\theta}(x_i)).$$
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Esto nos conduce a entender el costo de un solo dato como $-\log(P(x_i\;|\;y_i))$,, el cual se puede escribir como:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$$-\log(P(x_i\;|\;y_i))=-\big(y_i\log(h_{\theta}(x_i)) + (1-y_i)\log(1-h_{\theta}(x_i))\big).$$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Esta expresión se puede expresar como una función a tramos, conocida como la <strong>entropía cruzada</strong>, dada por:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$L_{EC}(h_{\theta}(\theta_i), y_i) = \begin{cases}-\log(h_\theta(x_i)) &amp; \mbox{ si } y_i=1 \\ -\log(1-h_\theta(x_i)) &amp; \mbox{ si } y_i = 0 \end{cases} $$
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="La-entrop&#237;a-cruzada-y-el-algoritmo-del-gradiente-descendente">La entrop&#237;a cruzada y el algoritmo del gradiente descendente<a class="anchor-link" href="#La-entrop&#237;a-cruzada-y-el-algoritmo-del-gradiente-descendente">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>El objetivo con el gradiente descendente es encontrar el valor optimo para $\theta$: minimizar la función de costo. En la siguiente ecuación se representa el hecho explicito de la función de costo $J$ paramétrizada por $\theta$.Así el objetivo es encontrar $\theta$ que para todos los ejemplos del conjunto de entrenamiento, $\theta$ es tal que la función de costo se minimiza:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$
\theta \in \operatorname*{argmin\,\,}_{ \theta\in \Omega} \frac{1}{m}\sum_{i=1}^{m}L_{CE}(f(x_i; \theta), y_i)= \operatorname*{argmin\,\,}_{ \theta\in \Omega} J(\theta).
$$
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Para emplear el algoritmo del gradiente descendente es necesario calcular $\nabla_\theta J(\theta)$ de tal manera que al regla de actualización para $\theta$ con base al gradiente es:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$\theta_{t+1} = \theta_{t} -\eta \nabla J(\theta_t).$$
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Teniendo presente la que función de entropía cruzada es:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$L_{EC}(h_{\theta}(\theta_i), y_i)=-\big(y_i\log(h_{\theta}(x_i)) + (1-y_i)\log(1-h_{\theta}(x_i))\big).$$
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Observe que la derivada para esta función en un vector de observación $x_i$ es:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$ \frac{\partial L_{EC}(h_{\theta}(\theta_i), y_i)}{\partial  \theta_j} = [h_\theta(x_i)-y]x_{i, j}.$$
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Note que el gradiente con respeto a $\theta_j$ representa de forma intuitiva, la diferencia entre el valor real $y_i$ y el valor estimado $h_\theta(x_i)$ por la observación $x_i$, multiplicado por el valor correspodiente a $x_{ij}$.Así cada derivada parcial del gradiente es de la forma:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$\frac{\partial J(\theta)}{\partial \theta_j } = \frac{1}{m}\sum_{i=1}^{m}[h_\theta(x_i)-y_i]x_{i,j}.$$
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Finalmente de la ecuación anterior, es fácil concluir que:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$\nabla_{\theta}J = X^{\top}[\hat{y}-y]$$
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>en donde $\hat{y} = [h_\theta(x_1),\dots, h_\theta(x_m)]$.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Implementaci&#243;n-de-la-regresi&#243;n-logistica-con-Scikit-learn">Implementaci&#243;n de la regresi&#243;n logistica con Scikit-learn<a class="anchor-link" href="#Implementaci&#243;n-de-la-regresi&#243;n-logistica-con-Scikit-learn">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Un ejercicio interesante para el lector es hacer la implementación de este módelo desde cero, sin embargo en esta ocasión no lo haremos así y veremos como hacer una implementación sencilla haciendo uso del modulo Scikit-learn de Python.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Para vamos a necesitar los siguiente modulos:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Cargamos lo datos, en este caso disponemos de un pequeño conjunto de datos que contiene la información básica (genero, edad, y salario estimado) de unos usuarios que compran ciertos productos en una tienda.  El objetivo acá es clasificar los usuarios entre aquellos que compran o no, esto con el objetivo de implementar alguna estrategía comercial</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data.csv&#39;</span><span class="p">)</span>
<span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[5]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>User ID</th>
      <th>Gender</th>
      <th>Age</th>
      <th>EstimatedSalary</th>
      <th>Purchased</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>15624510</td>
      <td>Male</td>
      <td>19</td>
      <td>19000</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>15810944</td>
      <td>Male</td>
      <td>35</td>
      <td>20000</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>15668575</td>
      <td>Female</td>
      <td>26</td>
      <td>43000</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>15603246</td>
      <td>Female</td>
      <td>27</td>
      <td>57000</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>15804002</td>
      <td>Male</td>
      <td>19</td>
      <td>76000</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Para hacernos una pequeña idea de la estructura de los datos, podemos construir varias visualizaciones entre las variables independientes (genero, edad y salario estimado) en relación con la variable objetivo (comprar). Por ejemplo, para la relación entre la <em>Age</em> y <em>Purchased</em> se obtiene el siguiente gráfico:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">Age</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">Purchased</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Como se puede apreciar los usuarios estan separados en dos clase, entre aquellos que hay comprado y aquellos que no.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Ahora vamos a dividir nuestro datos en dos partes, una parte sera el conjunto de entrenamiento y la otra el conjunto de testeo. Para hacer esto hacemos uso de <code>train_test_split</code> que se encuentra en el módulo <code>sklearn.model_selection</code>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">Age</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">Purchased</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.20</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Finalmente, hacemos uso de <code>LogisticRegression</code> que encuentra en el módulo <code>sklearn.linear_model</code> para entrenar nuestro modelo:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">y_train</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[8]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>LogisticRegression()</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Una vez se ha estimado la probabilidad $\hat{p}_i=h_\theta(x_i)$ decidir si $x_i$ pertenece a la clase con etiqueta $y_i=1$. Esto se hace con base a la partición de clases que se obtiene al clasicar la probabilidad estimada en clases mediante:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
$$\hat{y}_i=
\begin{cases} 
0 &amp; \mbox{ si } \hat{p}_i&lt;0.5; \\ 
1 &amp; \mbox{ si } \hat{p}_i \geq 0.5
\end{cases}$$
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Observe que $\sigma(t) &lt; 0$ cuando $t&lt;0$ y $\sigma(t)\geq 0.5$ cuando $t\geq 0$, así, una regresión logistica predice $1$ si $\theta^\top x_i$ es positivo, y $0$ si es negativo.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Analizando la calidad de las prediciones del modelo con los datos de testeo y visualizando los resultados:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAVSUlEQVR4nO3df5TVdZ3H8ddrZgCxjBFnhoxfg2QSW/68AQq1rtUCbgc7K/6gOLqdTvyx2WnPpuuwopUrB6s9ba26W9S2W2kZucFyALMO2jmlKAySoLLUQCqDIKOFW0Ip8N4/7p3xzsydey8z987gh+fjnHuY7+fz/X4+7+/nzH3N5fu9M9cRIQDAG1/NUBcAAKgMAh0AEkGgA0AiCHQASASBDgCJqBuqiRsaGqK5uXmopgeAN6TNmze/GBGNhfqGLNCbm5vV2to6VNMDwBuS7Wf76uOSCwAkgkAHgEQQ6ACQCAIdABJBoANAIkoGuu1v2d5v+8k++m37X2232d5q+/zKl4nj2aotezTz9gc1qWWtZt7+oFZt2VP1MZes2qbJi9epuWWtJi9epyWrtg24nmJjDsRHv7FBzS1rux4f/caGrr6dV1yrwzW1CluHa2q184prKzLnC9Pfq7C7Hi9Mf29X34a5V3Wbc8Pcq7offM89UnOzVFOT/feee8o/tp82Lb1T+04do6Ou0b5Tx2jT0jurPmc1lKq12ufiUn9t0fb7JP1B0nci4l0F+i+V9ClJl0qaLumrETG91MSZTCZ42+Ib36ote7T4R9t06LUjXW0jh9Vq2V+/Wx8+b2xVxlyyapvufvS5XsctnDFBmYmj+1VPsTFv+/C7+3UeUjbMH975217tMyeP1q0/+ZrOuO87cl57SNo1/xpN/uG3+z3nC9Pfq6aNv+g17v5ps7Rr9Ns048crevU9OudKXXj/D7LhvWiRdPDg6zucfLK0fLk23L26+LH9tGnpnXrX56/XyNf+1NV2aNgIPfnZf9bhX/y8KnNWw4a5VxWttVR/uWxvjohMwb5y/nyu7WZJa/oI9K9L+llEfD+3vUPSxRGxt9iYBHoaZt7+oPYcONSrfWz9SD3ccklVxpy8eJ2OFPi+rbX11lEn9aueYmPuXHbpMZ7B65pb1vbZ1/bFeaqLo73aD7tGdUePFDiiPGF3C42udklHXFN8zuZm6dkCb3OeOFGHn9tdlXr3nTpGbz2wv3d7fZMaXn6xKnNWw+Ga2qK1luovV7FAr8Q19LGSdudtt+faChWyyHar7daOjo4KTI2h9nyB8CzWXokxCwVvZ3t/6yk2ZrXUFnhyF2sflDmf6/2/lM72atXbdKBwFjQd6BiSNeqvUrUOxrkM6k3RiFgeEZmIyDQ2FvzNVbzBvK1+5DG1V2LMWhd6/Zlt7289xcasliMu/PTrq31Q5pwwofCBEyZUrd799YWzYH9945CsUX+VqnUwzqUSI+2RND5ve1yuDSeAG2afpZHDaru1jRxWqxtmn1W1MRdMH1/oMC2YPr7f9RQbcyBmTh7dZ/uzly9Uz9f/IenZyxcOaM7902YVHHf/tFnaNHt+wb5Ns+dnN5YuzV4zz3fyydLSpaWP7afd19+sQ8NGdGs7NGyEdl9/c9XmrIZStQ7KuUREyYekZklP9tH3V5Lul2RJMyRtLGfMCy64IJCGlY+3x0XL1kfzjWviomXrY+Xj7VUf86aVW+OMlrUx8cY1cUbL2rhp5dYB11NszIH4yPJHYuKNa7oeH1n+SFdf2/xr4jXXxFEpXnNNtM2/piJz7ps2K45KXY9902Z19T0y58pucz4y58ruB999d8TEiRF29t+77y7/2H7aeNsdsbe+KY7Isbe+KTbedkfV56yGUrVW4lwktUYfuVrOu1y+L+liSQ2SXpD0WUnDcj8Mvmbbku6UNEfSQUkfi4iSdzu5KQoAx67YTdGSf20xIhaU6A9Jn+xnbQCACjn+7iwAAPqFQAeARBDoAJAIAh0AEkGgA0AiCHQASASBDgCJINABIBEEOgAkgkAHgEQQ6ACQCAIdABJBoANAIgh0AEgEgQ4AiSDQASARBDoAJIJAB4BEEOgAkAgCHQASQaADQCIIdABIBIEOAIkg0AEgEQQ6ACSCQAeARBDoAJAIAh0AEkGgA0AiCHQASASBDgCJKCvQbc+xvcN2m+2WAv0TbD9ke4vtrbYvrXypAIBiSga67VpJd0maK2mqpAW2p/bYbYmkFRFxnqSrJf1bpQsFABRXziv0aZLaImJXRLwq6V5Jl/XYJyS9Jff1KEnPV65EAEA5ygn0sZJ2522359ryfU7SQtvtktZJ+lShgWwvst1qu7Wjo6Mf5QIA+lKpm6ILJP1XRIyTdKmk79ruNXZELI+ITERkGhsbKzQ1AEAqL9D3SBqftz0u15bv45JWSFJEbJB0kqSGShQIAChPOYG+SdKZtifZHq7sTc/VPfZ5TtL7Jcn2O5UNdK6pAMAgKhnoEXFY0nWSHpC0Xdl3szxl+1bb83K7fUbSJ2w/Ien7kv4mIqJaRQMAeqsrZ6eIWKfszc78tlvyvn5a0szKlgYAOBb8pigAJIJAB4BEEOgAkAgCHQASQaADQCIIdABIBIEOAIkg0AEgEQQ6ACSCQAeARBDoAJAIAh0AEkGgA0AiCHQASASBDgCJINABIBEEOgAkgkAHgEQQ6ACQCAIdABJBoANAIgh0AEgEgQ4AiSDQASARBDoAJIJAB4BEEOgAkAgCHQASQaADQCIIdABIRFmBbnuO7R2222y39LHPlbaftv2U7e9VtkwAQCl1pXawXSvpLkkflNQuaZPt1RHxdN4+Z0paLGlmRPzOdlO1CgYAFFbOK/RpktoiYldEvCrpXkmX9djnE5LuiojfSVJE7K9smQCAUsoJ9LGSdudtt+fa8r1D0jtsP2z7UdtzCg1ke5HtVtutHR0d/asYAFBQpW6K1kk6U9LFkhZI+obt+p47RcTyiMhERKaxsbFCUwMApPICfY+k8Xnb43Jt+dolrY6I1yLiN5J+pWzAAwAGSTmBvknSmbYn2R4u6WpJq3vss0rZV+ey3aDsJZhdlSsTAFBKyUCPiMOSrpP0gKTtklZExFO2b7U9L7fbA5Jesv20pIck3RARL1WraABAb46IIZk4k8lEa2vrkMwNAG9UtjdHRKZQH78pCgCJINABIBEEOgAkgkAHgEQQ6ACQCAIdABJBoANAIgh0AEgEgQ4AiSDQASARBDoAJIJAB4BEEOgAkAgCHQASQaADQCIIdABIBIEOAIkg0AEgEQQ6ACSCQAeARBDoAJAIAh0AEkGgA0AiCHQASASBDgCJINABIBEEOgAkgkAHgEQQ6ACQCAIdABJBoANAIsoKdNtzbO+w3Wa7pch+l9sO25nKlQgAKEfJQLddK+kuSXMlTZW0wPbUAvudIunTkh6rdJEAgNLKeYU+TVJbROyKiFcl3SvpsgL7/ZOkL0j6YwXrAwCUqZxAHytpd952e66ti+3zJY2PiLXFBrK9yHar7daOjo5jLhYA0LcB3xS1XSPpy5I+U2rfiFgeEZmIyDQ2Ng50agBAnnICfY+k8Xnb43JtnU6R9C5JP7P9jKQZklZzYxQABlc5gb5J0pm2J9keLulqSas7OyPi5YhoiIjmiGiW9KikeRHRWpWKAQAFlQz0iDgs6TpJD0jaLmlFRDxl+1bb86pdIACgPHXl7BQR6ySt69F2Sx/7XjzwsgAAx4rfFAWARBDoAJAIAh0AEkGgA0AiCHQASASBDgCJINABIBEEOgAkgkAHgEQQ6ACQCAIdABJBoANAIgh0AEgEgQ4AiSDQASARBDoAJIJAB4BEEOgAkAgCHQASQaADQCIIdABIBIEOAIkg0AEgEQQ6ACSCQAeARBDoAJAIAh0AEkGgA0AiCHQASASBDgCJKCvQbc+xvcN2m+2WAv1/b/tp21ttr7c9sfKlAgCKKRnotmsl3SVprqSpkhbYntpjty2SMhFxtqT7JH2x0oUCAIor5xX6NEltEbErIl6VdK+ky/J3iIiHIuJgbvNRSeMqWyYAoJRyAn2spN152+25tr58XNL9hTpsL7Ldaru1o6Oj/CoBACVV9Kao7YWSMpK+VKg/IpZHRCYiMo2NjZWcGgBOeHVl7LNH0vi87XG5tm5sf0DSTZL+PCL+VJnyAADlKucV+iZJZ9qeZHu4pKslrc7fwfZ5kr4uaV5E7K98mQCAUkoGekQclnSdpAckbZe0IiKesn2r7Xm53b4k6c2Sfmj7l7ZX9zEcAKBKyrnkoohYJ2ldj7Zb8r7+QIXrAgAcI35TFAASQaADQCIIdABIBIEOAIkg0AEgEQQ6ACSCQAeARBDoAJAIAh0AEkGgA0AiCHQASASBDgCJINABIBEEOgAkgkAHgEQQ6ACQCAIdABJBoANAIgh0AEgEgQ4AiSDQASARBDoAJIJAB4BEEOgAkAgCHQASQaADQCIIdABIBIEOAIkg0AEgEQQ6ACSCQAeARJQV6Lbn2N5hu812S4H+EbZ/kOt/zHZzxSuVtGHuVTpcU6uwdbimVhvmXlX1Y0sdt2npndp36hgddY32nTpGm5beWVZfsXH3vuU0hd312PuW07rNuXNMc7f+nWOaBzxnqfPc+s73dJtz6zvf83o9V1zb7didV1w74HX/Q92IbvP9oW5Et/4X6xu79b9Y39jV96tzZnTr+9U5M8pb9wlv777uE97ebc7+rt/BHudyMO9cVm3Zo5m3P6hJLWs18/YHtWrLnrLWp5Qlq7Zp8uJ1am5Zq8mL12nJqm1lH1utmjAIIqLoQ1KtpJ2SzpA0XNITkqb22OdvJX0t9/XVkn5QatwLLrggjsUjc66Mo1JE3uOoFI/MubJqx5Y6buNtd8TBYSO69R8cNiI23nZH0b5i4z5/yuiCfc+fMjoiItqaJhbsb2ua2O85S53nE1MyBfufmJKJtvnXFK5n/jX9Xvff1w4veNzva4dHRETHqIaC/R2jGmLH2dML9u04e3rxdR8/ufC6j59c8nuhWN8rfZzLK7XDY+Xj7TFlyf0x8cY1XY8pS+6PlY+3l/yeLuamlVu7jdn5uGnl1pLHVqsmVI6k1ugjV53t75vtCyV9LiJm57YX534QLMvb54HcPhts10naJ6kxigyeyWSitbW17B88h2tqVRdHe7e7RnVHj1Tl2FLH7Tt1jN56YH+v/n31TZLUZ1/Dyy/2OW5tHJUL1BKSHKGw++x/ob6pX3NKKnqexeY84pp+j9uXYvOVWgNJ/aq11LoX+16Q+j7PYuPOWrZeew4c6tU3tn6kHm65pMBR5Zm8eJ2OFHjq1drauezSosfOvP3BqtSEyrG9OSIyhfrqyjh+rKTdedvtkqb3tU9EHLb9sqTTJL3Yo5BFkhZJ0oQJE8oqvlNtgSdMsfZKHFvquKYDHQX7+2rv7LMK/5wr51yKKVZPf+as1toO9Dz7a7C/h0qN+3yB4CzWXq5CYV6sfTBqwuAY1JuiEbE8IjIRkWlsbCx9QJ4jLlxqX+2VOLbUcfvrC5/D/vrGon0DOZdi+jtntda2WufZX8fbeb6tfuQxtZer1oX+T9B3+2DUhMFRzjNrj6Txedvjcm0F98ldchkl6aVKFNhp0+z5vV5jRq69WseWOm739Tfr0LDuN+sODRuh3dffXLSv2Lj7ThldsG/fKaMlSbuaJhbs39U0sd9zljrPbVMyBfu3Tcno2csXFux79vKF/V73V2qHFzzuldrhkqSXRjUU7H9pVIN+ffb0gn2/Pnt68XUfP7nwuo+fLKn490KxvkN9nMuh2uG6YfZZGjmstlvfyGG1umH2WRqIBdPHH1N7vmrVhEHS18X1zoeyl2V2SZqk12+K/lmPfT6p7jdFV5Qa91hvikZkb0y95po4KsVrrinrhuhAjy113Mbb7oi99U1xRI699U2x8bY7yuorNm7njdHOR+cN0U6dN0Y7H21NEwc8Z6nz7Lwx2vl4Ykrm9XrmX9Pt2Lb51wx43TtvjHY+Om+Iduq8Mdr56BjV0NXXeWO087Hj7OnlrXvuxmjXuuduiA50/V7pcS6v5J3Lysfb46Jl66P5xjVx0bL1Fbv5eNPKrXFGy9qYeOOaOKNlbVk3RKtdEypDA7kpKkm2L5X0FWXf8fKtiFhq+9bcwKttnyTpu5LOk/RbSVdHxK5iYx7rTVEAwMBviioi1kla16Ptlryv/yjpioEUCQAYGH5TFAASQaADQCIIdABIBIEOAIko610uVZnY7pD07BBM3aAev8GKblif0lij4lif0gayRhMjouBvEQ5ZoA8V2619veUHrE85WKPiWJ/SqrVGXHIBgEQQ6ACQiBMx0JcPdQHHOdanNNaoONantKqs0Ql3DR0AUnUivkIHgCQR6ACQiGQD3fZ42w/Zftr2U7Y/nWsfbfuntn+d+/fUoa51qNg+yfZG20/k1ujzufZJuQ/7bst9+Pfwoa51KNmutb3F9prcNuuTx/YztrfZ/qXt1lwbz7Mc2/W277P9v7a3276wWuuTbKBLOizpMxExVdIMSZ+0PVVSi6T1EXGmpPW57RPVnyRdEhHnSDpX0hzbMyR9QdK/RMTbJf1O0seHrsTjwqclbc/bZn16+4uIODfvvdU8z173VUk/jogpks5R9nupOuvT1x9KT+0h6X8kfVDSDkmn59pOl7RjqGs7Hh6STpb0uLKfF/uipLpc+4WSHhjq+oZwXcblnnCXSFqj7GdQsz7d1+gZSQ092nieZc99lKTfKPcGlGqvT8qv0LvYblb2wzcekzQmIvbmuvZJGjNUdR0PcpcTfilpv6SfStop6UBEHM7t0q7sh4CfqL4i6R8kdX7i82lifXoKST+xvTn3QfASz7NOkyR1SPrP3GW7b9p+k6q0PskHuu03S/pvSX8XEf+X3xfZH48n9Ps2I+JIRJyr7CvRaZKmDG1Fxw/bH5K0PyI2D3Utx7lZEXG+pLnKXtp8X37nCf48q5N0vqR/j4jzJL2iHpdXKrk+SQe67WHKhvk9EfGjXPMLtk/P9Z+u7CvTE15EHJD0kLKXEOpzH/YtFf5Q8BPFTEnzbD8j6V5lL7t8VaxPNxGxJ/fvfkkrlX1hwPMsq11Se0Q8ltu+T9mAr8r6JBvoti3pPyRtj4gv53WtlnRt7utrlb22fkKy3Wi7Pvf1SGXvMWxXNtjn53Y7YdcoIhZHxLiIaFb2w88fjIiPivXpYvtNtk/p/FrSX0p6UjzPJEkRsU/Sbttn5ZreL+lpVWl9kv1NUduzJP1c0ja9fv3zH5W9jr5C0gRl/3zvlRHx2yEpcojZPlvSt5X98O8aSSsi4lbbZyj7inS0pC2SFkbEn4au0qFn+2JJ10fEh1if1+XWYmVus07S9yL7IfKnieeZJMn2uZK+KWm4pF2SPqbc800VXp9kAx0ATjTJXnIBgBMNgQ4AiSDQASARBDoAJIJAB4BEEOgAkAgCHQAS8f+ZGP/XDaHigAAAAABJRU5ErkJggg==
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[11]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy = </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">y_test</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Accuracy = 0.825
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Bibliograf&#237;a">Bibliograf&#237;a<a class="anchor-link" href="#Bibliograf&#237;a">&#182;</a></h2><ul>
<li>Mustafa Murat Arat. 2019. <a src='https://mmuratarat.github.io/2019-01-07/logistic-regression-in-Tensorflow'>Logistic Regression in Tensorflow.</a></li>
<li><a src ='https://www.andrewng.org/'>Andrew Ng</a>. <a scr='http://cs229.stanford.edu/materials.html'>Machine learning course materials</a>. Technical report, University of Stanford.</li>
<li>Aurelien Geron. 2019. Hands-on Machine Learning with Scikit-Learn, Keras and TensorFlow.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Contacto">Contacto<a class="anchor-link" href="#Contacto">&#182;</a></h2><ul>
<li>Participa de la canal de Nerve a través de <a src='https://discord.gg/edPmghPq8K'>Discord</a>.</li>
<li>Se quieres conocer más acerca de este tema me puedes contactar a través de <a src='https://www.classgap.com/me/alejandro-sanchez-yali'>Classgap</a>.</li>
</ul>

</div>
</div>
</div>
 

